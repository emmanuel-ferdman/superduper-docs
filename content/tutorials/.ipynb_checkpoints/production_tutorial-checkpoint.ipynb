{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66361435-4ae2-4dc4-9332-7cb6608dc7df",
   "metadata": {},
   "source": [
    "# Production features tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680091ee-1414-4c2b-b31d-54f858e4cc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dodo//superduper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/.pyenv/versions/3.11.7/envs/superduper-3.11/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52de46d1-18d2-4355-84f3-89965ebe9934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stack(identifier='rag', uuid='37e587f3-91e8-4a4f-b286-2d32398dd0b3', components=[VectorIndex(identifier='my-index', uuid='a32aae9a-465c-4041-aa82-ecbebbb4e0fb', indexing_listener=Listener(identifier='my-listener', uuid='f2a5cc60-9308-4146-8370-4c0b787292e3', key='txt', model=SentenceTransformer(preferred_devices=['cuda', 'mps', 'cpu'], device='cpu', identifier='my-embedding', uuid='a34389e8-12bf-4bf3-bca7-bbe5c027d859', signature='*args,**kwargs', datatype=DataType(identifier='my-vec', uuid='2ba7a2ee-0bb7-46e0-853b-b9ee47c47da5', encoder=None, decoder=None, info=None, shape=(384,), directory=None, encodable='native', bytes_encoding=<BytesEncoding.BYTES: 'Bytes'>, intermediate_type='bytes', media_type=None), output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={'show_progress_bar': True}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, object=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model='all-MiniLM-L6-v2', preprocess=None, postprocess=Code(identifier='', uuid='2c9da7eb-8fdf-4fe6-9c0d-d1f1dd056f6f', code='from superduper import code\\n\\n@code\\ndef postprocess(x):\\n    return x.tolist()\\n')), select=docu.find(), active=True, predict_kwargs={'max_chunk_size': 50}), compatible_listener=None, measure='cosine', metric_values={}), SequentialModel(identifier='rag', uuid='c95f5400-c9d4-4cf7-99e3-ec86b685e7f1', signature='**kwargs', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, models=[RetrievalPrompt(identifier='my-prompt', uuid='5e165724-d78f-47b9-b4e0-f782f21eecf7', signature='**kwargs', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, preprocess=None, postprocess=Code(identifier='', uuid='9d1e182d-42bc-4ec2-857f-06fb4008dee2', code=\"from superduper import code\\n\\n@code\\ndef get_output(c):\\n    return [r['txt'] for r in c]\\n\"), select=docu.like(documents[0], vector_index=\"my-index\", n=5).find().limit(10), prompt_explanation=\"HERE ARE SOME FACTS SEPARATED BY '---' IN OUR DATA REPOSITORY WHICH WILL HELP YOU ANSWER THE QUESTION.\", prompt_introduction='HERE IS THE QUESTION WHICH YOU SHOULD ANSWER BASED ONLY ON THE PREVIOUS FACTS:', join='\\n---\\n'), OpenAIChatCompletion(identifier='gpt-3.5-turbo', uuid='eb850e54-e5b3-49a2-806c-77808f520a05', signature='singleton', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, model='gpt-3.5-turbo', max_batch_size=8, openai_api_key=None, openai_api_base=None, client_kwargs={}, batch_size=1, prompt='')])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('docs/content/tutorials/text.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "from superduper import superduper\n",
    "\n",
    "db = superduper()\n",
    "\n",
    "db['documentation'].insert_many(data).execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
